# -*- coding: utf-8 -*-
"""eval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aXlGN2zafrhmXzP1Vhyl2mSb4P7sCR6-
"""

# src/eval.py

"""
Evaluation script for the Neocognitron-inspired model.

Usage example:
    python -m src.eval \
        --data_dir data \
        --batch_size 128 \
        --checkpoint results/checkpoints/best_model.pt \
        --device cpu \
        --output_dir results
"""

import argparse
import os

import matplotlib.pyplot as plt
import numpy as np
import torch
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from torch.utils.data import DataLoader

from src.data.dataset_loader import get_mnist_dataloaders
from src.models.neocognitron import Neocognitron


def parse_args() -> argparse.Namespace:
    """Parse command-line arguments for evaluation."""
    parser = argparse.ArgumentParser(description="Evaluate Neocognitron model on MNIST.")

    parser.add_argument("--data_dir", type=str, default="data", help="Directory for MNIST data.")
    parser.add_argument("--batch_size", type=int, default=128, help="Batch size for evaluation.")
    parser.add_argument(
        "--checkpoint",
        type=str,
        required=True,
        help="Path to model checkpoint (.pt file).",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cpu",
        choices=["cuda", "cpu"],
        help="Device to use.",
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="results",
        help="Directory to save confusion matrix.",
    )

    return parser.parse_args()


def evaluate_test_set(
    model: torch.nn.Module,
    dataloader: DataLoader,
    device: torch.device,
) -> None:
    """
    Evaluate model on test set and save confusion matrix.

    Args:
        model: Trained model.
        dataloader: Test DataLoader.
        device: torch.device.
    """
    model.eval()
    all_labels = []
    all_preds = []

    total_correct = 0
    total_samples = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images = images.to(device)
            labels = labels.to(device)

            logits = model(images)
            preds = logits.argmax(dim=1)

            total_correct += (preds == labels).sum().item()
            total_samples += labels.size(0)

            all_labels.extend(labels.cpu().numpy().tolist())
            all_preds.extend(preds.cpu().numpy().tolist())

    acc = total_correct / total_samples
    print(f"Test Accuracy: {acc:.4f}")

    # Confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(10)))

    fig, ax = plt.subplots(figsize=(6, 6))
    disp.plot(ax=ax, values_format="d", cmap="Blues", colorbar=False)
    plt.title("Confusion Matrix (MNIST)")
    plt.tight_layout()

    os.makedirs("results", exist_ok=True)
    plt.savefig(os.path.join("results", "confusion_matrix.png"))
    plt.close()
    print("Saved confusion matrix to results/confusion_matrix.png")


def main() -> None:
    """Main evaluation routine."""
    args = parse_args()

    device = torch.device("cuda" if args.device == "cuda" and torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Get only test loader
    _, _, test_loader = get_mnist_dataloaders(
        data_dir=args.data_dir,
        batch_size=args.batch_size,
    )

    # Create model and load weights
    model = Neocognitron(input_channels=1, num_classes=10).to(device)
    state_dict = torch.load(args.checkpoint, map_location=device)
    model.load_state_dict(state_dict)

    evaluate_test_set(model, test_loader, device)


if __name__ == "__main__":
    main()