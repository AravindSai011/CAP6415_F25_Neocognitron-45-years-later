# -*- coding: utf-8 -*-
"""demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bch2EPqMYTznlpwkPZQ1_MvMZF4WkRJi
"""

# src/demo.py

"""
Demo script for the Neocognitron-inspired model.

This is meant to be used in the video demo:
    - Shows some sample predictions on MNIST test images
    - Applies small translations (shifts) to demonstrate position tolerance

Usage example:
    python -m src.demo \
        --data_dir data \
        --batch_size 16 \
        --checkpoint results/checkpoints/best_model.pt \
        --device cpu \
        --output_dir results/sample_predictions
"""

import argparse
import os

import matplotlib.pyplot as plt
import torch
from torch.utils.data import DataLoader

from src.data.dataset_loader import get_mnist_dataloaders
from src.models.neocognitron import Neocognitron


def parse_args() -> argparse.Namespace:
    """Parse arguments for the demo script."""
    parser = argparse.ArgumentParser(description="Demo Neocognitron model on sample MNIST images.")

    parser.add_argument("--data_dir", type=str, default="data", help="Directory for MNIST data.")
    parser.add_argument("--batch_size", type=int, default=16, help="Batch size for demo samples.")
    parser.add_argument(
        "--checkpoint",
        type=str,
        required=True,
        help="Path to trained model checkpoint.",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cpu",
        choices=["cuda", "cpu"],
        help="Device to use.",
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="results/sample_predictions",
        help="Directory to save demo images.",
    )

    return parser.parse_args()


def demo_samples(
    model: torch.nn.Module,
    dataloader: DataLoader,
    device: torch.device,
    output_dir: str,
    num_batches: int = 1,
) -> None:
    """
    Run demo on a few batches of test images.

    For each sample:
        - Show the original image and its predicted label
        - Apply a small translation (shift) and show the new prediction

    Args:
        model: Trained model.
        dataloader: Test DataLoader.
        device: torch.device.
        output_dir: Directory to save output images.
        num_batches: Number of batches to visualize.
    """
    model.eval()
    os.makedirs(output_dir, exist_ok=True)

    batch_count = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images = images.to(device)
            labels = labels.to(device)

            logits = model(images)
            preds = logits.argmax(dim=1)

            # For demo, apply a small translation (shift) using torch.roll
            shifted_images = torch.roll(images, shifts=(2, 2), dims=(2, 3))
            shifted_logits = model(shifted_images)
            shifted_preds = shifted_logits.argmax(dim=1)

            batch_size = images.size(0)

            for i in range(batch_size):
                fig, axes = plt.subplots(1, 2, figsize=(4, 2))

                # Original image
                axes[0].imshow(images[i].cpu().squeeze(), cmap="gray")
                axes[0].set_title(f"Orig: {labels[i].item()} / Pred: {preds[i].item()}")
                axes[0].axis("off")

                # Shifted image
                axes[1].imshow(shifted_images[i].cpu().squeeze(), cmap="gray")
                axes[1].set_title(f"Shifted Pred: {shifted_preds[i].item()}")
                axes[1].axis("off")

                plt.tight_layout()
                save_path = os.path.join(output_dir, f"sample_{batch_count}_{i}.png")
                plt.savefig(save_path)
                plt.close()

            batch_count += 1
            if batch_count >= num_batches:
                break

    print(f"Saved demo images to {output_dir}")


def main() -> None:
    """Main demo routine."""
    args = parse_args()
    device = torch.device("cuda" if args.device == "cuda" and torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Only need the test loader
    _, _, test_loader = get_mnist_dataloaders(
        data_dir=args.data_dir,
        batch_size=args.batch_size,
    )

    model = Neocognitron(input_channels=1, num_classes=10).to(device)
    state_dict = torch.load(args.checkpoint, map_location=device)
    model.load_state_dict(state_dict)

    demo_samples(model, test_loader, device, args.output_dir, num_batches=1)


if __name__ == "__main__":
    main()