# -*- coding: utf-8 -*-
"""data/dataset_loader.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cMfcBZGigX3HtoVFy4XUwuCm2sL2nRRA
"""

# src/data/dataset_loader.py

"""
Dataset loading utilities for the Neocognitron project.

Currently supports MNIST. Provides train, validation, and test DataLoaders.
"""

from typing import Tuple

import torch
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms


def get_mnist_dataloaders(
    data_dir: str,
    batch_size: int,
    num_workers: int = 2,
    val_split: float = 0.1,
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    Create train/validation/test DataLoaders for MNIST.

    Args:
        data_dir: Directory where MNIST will be downloaded/stored.
        batch_size: Batch size for all loaders.
        num_workers: Number of worker processes for loading data.
        val_split: Fraction of training data to use for validation.

    Returns:
        train_loader, val_loader, test_loader
    """
    # Transform: convert to tensor and normalize to mean 0.1307, std 0.3081 (standard MNIST)
    transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,)),
        ]
    )

    # Download / load training and test datasets
    train_full = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)
    test_set = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)

    # Split training into train and validation
    val_size = int(len(train_full) * val_split)
    train_size = len(train_full) - val_size
    train_set, val_set = random_split(train_full, [train_size, val_size])

    # Create DataLoaders
    train_loader = DataLoader(
        train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True
    )
    val_loader = DataLoader(
        val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True
    )
    test_loader = DataLoader(
        test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True
    )

    return train_loader, val_loader, test_loader

